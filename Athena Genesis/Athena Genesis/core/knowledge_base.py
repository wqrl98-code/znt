# æ–‡ä»¶è·¯å¾„: core/knowledge_base.py
# -*- coding: utf-8 -*-
import os
import json
import threading
import jieba
import re
import time
from datetime import datetime
from config.settings import SETTINGS


class KnowledgeBase:
    def __init__(self):
        # è·å–çŸ¥è¯†åº“è·¯å¾„
        kb_dir = SETTINGS.PATHS.directories.get('knowledge_base')
        if not kb_dir:
            # å¦‚æœæ²¡æœ‰é…ç½®è·¯å¾„ï¼Œä½¿ç”¨é»˜è®¤è·¯å¾„
            kb_dir = os.path.join(os.getcwd(), 'ATHENA_WORKSPACE', 'KnowledgeBase')

        # ç¡®ä¿ç›®å½•å­˜åœ¨
        if not os.path.exists(kb_dir):
            os.makedirs(kb_dir, exist_ok=True)

        # æ•°æ®åº“æ–‡ä»¶è·¯å¾„
        self.db_path = os.path.join(kb_dir, "global_index.json")

        # å†…å­˜æ•°æ®ç»“æ„
        self.data = {
            "documents": {},
            "metadata": {
                "total_docs": 0,
                "total_words": 0,
                "last_updated": "",
                "created_at": datetime.now().isoformat()
            }
        }

        # ğŸ”¥ğŸ”¥ğŸ”¥ã€æ ¸å¿ƒä¿®å¤ã€‘ä½¿ç”¨å¯é‡å…¥é” (RLock) ğŸ”¥ğŸ”¥ğŸ”¥
        # å°† Lock æ”¹ä¸º RLockï¼Œé˜²æ­¢ ensure_loaded è°ƒç”¨ load_db æ—¶å‘ç”Ÿæ­»é”
        self.lock = threading.RLock()

        # å»¶è¿ŸåŠ è½½æ ‡å¿—
        self._loaded = False

        print(f"ğŸ“š çŸ¥è¯†åº“åˆå§‹åŒ–å®Œæˆï¼Œè·¯å¾„: {self.db_path}")

    def ensure_loaded(self):
        """ç¡®ä¿æ•°æ®å·²åŠ è½½"""
        if not self._loaded:
            # ä½¿ç”¨RLockï¼Œå…è®¸åŒä¸€ä¸ªçº¿ç¨‹é‡å…¥
            with self.lock:
                # åŒé‡æ£€æŸ¥ï¼Œé˜²æ­¢å¤šä¸ªçº¿ç¨‹åŒæ—¶è¿›å…¥
                if not self._loaded:
                    print("ğŸ” æ­£åœ¨åŠ è½½çŸ¥è¯†åº“æ•°æ®...")
                    self.load_db()
                    self._loaded = True
                    print(f"âœ… çŸ¥è¯†åº“åŠ è½½å®Œæˆ: {len(self.data['documents'])} ä¸ªæ–‡æ¡£")

    def load_db(self):
        """åŠ è½½æ•°æ®åº“"""
        # æ³¨æ„ï¼šè¿™é‡Œä¸å†éœ€è¦with self.lockï¼Œå› ä¸ºensure_loadedå·²ç»åŠ é”
        # è€Œä¸”ç”±äºæ˜¯RLockï¼ŒåŒä¸€ä¸ªçº¿ç¨‹å¯ä»¥é‡å…¥ï¼Œä½†è¿™é‡Œæˆ‘ä»¬ä¸éœ€è¦å†æ¬¡åŠ é”
        try:
            if os.path.exists(self.db_path):
                with open(self.db_path, 'r', encoding='utf-8') as f:
                    loaded_data = json.load(f)

                # åˆå¹¶æ•°æ®ï¼Œä¿ç•™åŸæœ‰ç»“æ„
                if "documents" in loaded_data:
                    self.data["documents"] = loaded_data["documents"]

                # æ›´æ–°å…ƒæ•°æ®
                if "metadata" in loaded_data:
                    # ä¿ç•™åŸæœ‰åˆ›å»ºæ—¶é—´
                    if "created_at" in loaded_data["metadata"]:
                        self.data["metadata"]["created_at"] = loaded_data["metadata"]["created_at"]

                    # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
                    self.data["metadata"]["total_docs"] = len(self.data["documents"])
                    self.data["metadata"]["total_words"] = sum(
                        doc.get("length", 0) for doc in self.data["documents"].values()
                    )
                    self.data["metadata"]["last_updated"] = datetime.now().isoformat()
                else:
                    # å¦‚æœæ²¡æœ‰å…ƒæ•°æ®ï¼Œåˆ›å»ºé»˜è®¤
                    self.data["metadata"]["total_docs"] = len(self.data["documents"])
                    self.data["metadata"]["total_words"] = sum(
                        doc.get("length", 0) for doc in self.data["documents"].values()
                    )
                    self.data["metadata"]["last_updated"] = datetime.now().isoformat()

                print(f"ğŸ“– ä»ç£ç›˜åŠ è½½äº† {len(self.data['documents'])} ä¸ªæ–‡æ¡£")
                return True
            else:
                print("ğŸ“ çŸ¥è¯†åº“æ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ›å»ºæ–°æ•°æ®åº“")
                # ä¿å­˜ç©ºçš„æ•°æ®åº“
                self.save_db()
                return False

        except Exception as e:
            print(f"âŒ åŠ è½½çŸ¥è¯†åº“å¤±è´¥: {e}")
            # åˆ›å»ºæ–°çš„æ•°æ®ç»“æ„
            self.data = {
                "documents": {},
                "metadata": {
                    "total_docs": 0,
                    "total_words": 0,
                    "last_updated": datetime.now().isoformat(),
                    "created_at": datetime.now().isoformat()
                }
            }
            return False

    def save_db(self):
        """ä¿å­˜æ•°æ®åº“"""
        with self.lock:  # RLockï¼Œå…è®¸åŒä¸€ä¸ªçº¿ç¨‹é‡å…¥
            try:
                # ç¡®ä¿ç›®å½•å­˜åœ¨
                db_dir = os.path.dirname(self.db_path)
                if not os.path.exists(db_dir):
                    os.makedirs(db_dir, exist_ok=True)

                # æ›´æ–°å…ƒæ•°æ®
                self.data["metadata"]["total_docs"] = len(self.data["documents"])
                self.data["metadata"]["total_words"] = sum(
                    doc.get("length", 0) for doc in self.data["documents"].values()
                )
                self.data["metadata"]["last_updated"] = datetime.now().isoformat()

                # ä¿å­˜åˆ°æ–‡ä»¶
                with open(self.db_path, 'w', encoding='utf-8') as f:
                    json.dump(self.data, f, ensure_ascii=False, indent=2)

                # print(f"ğŸ’¾ çŸ¥è¯†åº“å·²ä¿å­˜åˆ°: {self.db_path}")
                return True

            except Exception as e:
                print(f"âŒ ä¿å­˜çŸ¥è¯†åº“å¤±è´¥: {e}")
                return False

    def clear_db(self):
        """æ¸…ç©ºæ•°æ®åº“"""
        with self.lock:
            self.data = {
                "documents": {},
                "metadata": {
                    "total_docs": 0,
                    "total_words": 0,
                    "last_updated": datetime.now().isoformat(),
                    "created_at": self.data["metadata"].get("created_at", datetime.now().isoformat())
                }
            }
            self._loaded = True  # æ ‡è®°ä¸ºå·²åŠ è½½ï¼Œé˜²æ­¢å†æ¬¡åŠ è½½
            self.save_db()
            print("ğŸ§¹ [KnowledgeBase] å†…å­˜ç´¢å¼•å·²æ¸…ç©º")

    def add_document(self, filename, content, keywords, metadata=None):
        """æ·»åŠ æ–‡æ¡£åˆ°ç´¢å¼•"""
        if metadata is None:
            metadata = {}

        self.ensure_loaded()

        with self.lock:
            # æ£€æŸ¥æ–‡æ¡£æ˜¯å¦å·²å­˜åœ¨
            if filename in self.data["documents"]:
                print(f"âš ï¸ æ–‡æ¡£å·²å­˜åœ¨ï¼Œæ›´æ–°: {filename}")

            # ç®€å•çš„æ‘˜è¦ç”Ÿæˆ (å–å‰200å­—)
            summary = content[:200].replace('\n', ' ') + "..."

            # ç¡®ä¿keywordsæ˜¯å­—å…¸æ ¼å¼
            if isinstance(keywords, list):
                # å¦‚æœæ˜¯åˆ—è¡¨ï¼Œè½¬æ¢ä¸ºå­—å…¸ï¼ˆè¯é¢‘ä¸º1ï¼‰
                keywords_dict = {kw: 1 for kw in keywords}
            elif isinstance(keywords, dict):
                keywords_dict = keywords
            else:
                keywords_dict = {}

            self.data["documents"][filename] = {
                "content": content,
                "keywords": keywords_dict,
                "summary": summary,
                "metadata": metadata,
                "length": len(content),
                "added_at": datetime.now().isoformat(),
                "updated_at": datetime.now().isoformat()
            }

            # è‡ªåŠ¨ä¿å­˜
            self.save_db()
            print(f"ğŸ“š [KnowledgeBase] å·²ç´¢å¼•æ–‡æ¡£: {filename}")

            return True

    def search(self, query, top_k=3):
        """
        ç®€å•çš„å…³é”®è¯æœç´¢
        è¿”å›: æ‹¼æ¥å¥½çš„å‚è€ƒæ–‡æœ¬å­—ç¬¦ä¸²
        """
        self.ensure_loaded()

        if not query or not query.strip():
            return ""

        # åˆ†è¯
        query_words = set(jieba.lcut(query))
        scores = []

        # åˆ›å»ºæ•°æ®å¿«ç…§ï¼Œå‡å°‘é”æŒæœ‰æ—¶é—´
        documents_snapshot = {}
        with self.lock:
            documents_snapshot = self.data["documents"].copy()

        for fname, doc_data in documents_snapshot.items():
            score = 0
            content = doc_data.get("content", "")
            doc_keywords = doc_data.get("keywords", {})

            # 1. æ ‡é¢˜å‘½ä¸­æƒé‡
            if query in fname:
                score += 10

            # 2. å…³é”®è¯å‘½ä¸­æƒé‡
            for qw in query_words:
                if qw in doc_keywords:
                    score += doc_keywords[qw]  # åŠ ä¸Šè¯é¢‘
                elif qw in content:
                    score += 1

            if score > 0:
                scores.append((score, fname, doc_data))

        # æŒ‰åˆ†æ•°æ’åº
        scores.sort(key=lambda x: x[0], reverse=True)

        # ç»„è£…ç»“æœ
        results = []
        for score, fname, doc_data in scores[:top_k]:
            snippet = doc_data.get("summary", "")
            # å¦‚æœæ˜¯æ·±åº¦æœç´¢ï¼Œå¯ä»¥è¿”å›æ›´å¤šå†…å®¹
            results.append(f"ã€æ¥æº: {fname} (åŒ¹é…åº¦:{score})ã€‘\n{snippet}\n")

        if not results:
            return ""  # æœªæ‰¾åˆ°

        return "\n".join(results)

    def get_all_docs(self):
        """è·å–æ‰€æœ‰æ–‡æ¡£åˆ—è¡¨"""
        self.ensure_loaded()
        with self.lock:
            return list(self.data["documents"].keys())

    def get_doc_count(self):
        """è·å–æ–‡æ¡£æ•°é‡"""
        self.ensure_loaded()
        with self.lock:
            return len(self.data["documents"])

    def get_total_words(self):
        """è·å–æ€»å­—æ•°"""
        self.ensure_loaded()
        with self.lock:
            return self.data["metadata"].get("total_words", 0)

    def remove_document(self, filename):
        """ç§»é™¤æ–‡æ¡£"""
        self.ensure_loaded()
        with self.lock:
            if filename in self.data["documents"]:
                del self.data["documents"][filename]
                self.save_db()
                print(f"ğŸ—‘ï¸ [KnowledgeBase] å·²ç§»é™¤æ–‡æ¡£: {filename}")
                return True
            return False

    def get_document(self, filename):
        """è·å–ç‰¹å®šæ–‡æ¡£"""
        self.ensure_loaded()
        with self.lock:
            return self.data["documents"].get(filename)

    def update_document(self, filename, content=None, keywords=None, metadata=None):
        """æ›´æ–°æ–‡æ¡£"""
        self.ensure_loaded()
        with self.lock:
            if filename in self.data["documents"]:
                doc = self.data["documents"][filename]

                if content is not None:
                    doc["content"] = content
                    doc["length"] = len(content)
                    # æ›´æ–°æ‘˜è¦
                    doc["summary"] = content[:200].replace('\n', ' ') + "..."

                if keywords is not None:
                    if isinstance(keywords, list):
                        doc["keywords"] = {kw: 1 for kw in keywords}
                    elif isinstance(keywords, dict):
                        doc["keywords"] = keywords

                if metadata is not None:
                    doc["metadata"].update(metadata)

                doc["updated_at"] = datetime.now().isoformat()

                self.save_db()
                print(f"ğŸ”„ [KnowledgeBase] å·²æ›´æ–°æ–‡æ¡£: {filename}")
                return True
            return False

    def get_stats(self):
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        self.ensure_loaded()
        with self.lock:
            return {
                "total_documents": len(self.data["documents"]),
                "total_words": self.data["metadata"].get("total_words", 0),
                "last_updated": self.data["metadata"].get("last_updated", ""),
                "created_at": self.data["metadata"].get("created_at", ""),
                "db_path": self.db_path
            }

    def backup(self, backup_path=None):
        """å¤‡ä»½çŸ¥è¯†åº“"""
        self.ensure_loaded()
        with self.lock:
            if backup_path is None:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                backup_dir = os.path.join(os.path.dirname(self.db_path), "backups")
                if not os.path.exists(backup_dir):
                    os.makedirs(backup_dir, exist_ok=True)
                backup_path = os.path.join(backup_dir, f"knowledge_backup_{timestamp}.json")

            try:
                with open(backup_path, 'w', encoding='utf-8') as f:
                    json.dump(self.data, f, ensure_ascii=False, indent=2)
                print(f"ğŸ’¾ çŸ¥è¯†åº“å·²å¤‡ä»½åˆ°: {backup_path}")
                return True
            except Exception as e:
                print(f"âŒ å¤‡ä»½å¤±è´¥: {e}")
                return False

    def restore_from_backup(self, backup_path):
        """ä»å¤‡ä»½æ¢å¤"""
        try:
            with open(backup_path, 'r', encoding='utf-8') as f:
                backup_data = json.load(f)

            with self.lock:
                self.data = backup_data
                self._loaded = True
                self.save_db()

            print(f"â™»ï¸ å·²ä»å¤‡ä»½æ¢å¤: {backup_path}")
            return True

        except Exception as e:
            print(f"âŒ æ¢å¤å¤±è´¥: {e}")
            return False
