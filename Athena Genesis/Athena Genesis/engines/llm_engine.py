# -*- coding: utf-8 -*-
"""
LLM Engine - é«˜æ•ˆè¿æ¥ç¨³å®šç‰ˆ (v21.1)
åˆå¹¶ä¿®å¤ï¼šSession å¤ç”¨è¿æ¥ + è¶…é•¿è¶…æ—¶ + ç®—åŠ›ä¼°ç®— + å®Œæ•´é”™è¯¯å¤„ç†
æ”¯æŒè‡ªå®šä¹‰ options å‚æ•°
"""
import requests
import json
import time
import math
import traceback
from config.settings import SETTINGS


class LLMEngine:
    def __init__(self):
        self.base_url = SETTINGS.OLLAMA_API_URL if hasattr(SETTINGS, 'OLLAMA_API_URL') else "http://localhost:11434"
        self.model = SETTINGS.OLLAMA_MODEL if hasattr(SETTINGS, 'OLLAMA_MODEL') else "qwen3:8b"
        # ğŸ”¥ æ ¸å¿ƒä¿®æ”¹ï¼šå°†è¶…æ—¶æ—¶é—´è®¾ä¸º 1 å°æ—¶ï¼Œé€‚åº”ä½ç®—åŠ›ä¸‹çš„é•¿æ–‡ç”Ÿæˆ
        self.timeout = 3600
        # ä½¿ç”¨ Session å¤ç”¨ TCP è¿æ¥ï¼Œæé«˜æ•ˆç‡
        self.session = requests.Session()

    def estimate_time(self, context_length, predict_length):
        """
        ğŸš€ ç®—åŠ›è€—æ—¶ä¼°ç®—å™¨
        æ ¹æ®å½“å‰ä¸Šä¸‹æ–‡é•¿åº¦å’Œé¢„ä¼°è¾“å‡ºé•¿åº¦ï¼Œè®¡ç®—å¤§è‡´ç­‰å¾…æ—¶é—´
        """
        # å‡è®¾ä½ç®—åŠ›åœºæ™¯ (CPU/å†…å­˜å¸è½½æ¨¡å¼)
        # å¤„ç† Prompt é€Ÿåº¦: çº¦ 10-20 token/s
        # ç”Ÿæˆé€Ÿåº¦: çº¦ 1-3 token/s

        process_time = context_length / 15.0  # é¢„å¤„ç†è€—æ—¶
        gen_time = predict_length / 1.5  # ç”Ÿæˆè€—æ—¶ (æŒ‰æœ€æ…¢ä¼°ç®—)

        total_seconds = process_time + gen_time
        return total_seconds

    def chat(self, user_text, system_prompt=None, options=None):
        """
        æ ‡å‡†å¯¹è¯æ¥å£ (éæµå¼ï¼Œä¿è¯å®Œæ•´æ€§)
        æ”¯æŒä¼ é€’ options (å¦‚ num_ctx, temperature) å‚æ•°
        ä½¿ç”¨ Session å¤ç”¨è¿æ¥æé«˜æ•ˆç‡
        """
        if options is None:
            options = {}

        # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
        messages = []
        if system_prompt:
            messages.append({"role": "system", "content": system_prompt})
        messages.append({"role": "user", "content": user_text})

        # é»˜è®¤æ»¡è¡€å‚æ•° (ç»ä¸é™çº§)
        default_options = {
            "temperature": 0.6,  # ç¨å¾®é™ä½éšæœºæ€§ï¼Œä¿è¯è§£è¯»å‡†ç¡®
            "num_ctx": 12288,  # å¼ºåˆ¶æ‰©å¤§ä¸Šä¸‹æ–‡çª—å£åˆ° 12kï¼Œé€‚é…é•¿æ–‡
            "num_predict": 4096,  # å…è®¸é•¿è¾“å‡º
            "num_gpu": 999  # å°½åŠ›è°ƒç”¨ GPU
        }

        # ğŸ”¥ å…³é”®ä¿®å¤ï¼šç¡®ä¿ä¼ å…¥çš„ options è¦†ç›– default_options
        final_options = default_options.copy()
        if options:
            final_options.update(options)  # è¿™æ ·æœ€ç¨³å¦¥

        payload = {
            "model": self.model,
            "stream": False,  # å¼ºåˆ¶éæµå¼ï¼Œé¿å…UIå¤„ç†å¤æ‚
            "messages": messages,
            "options": final_options
        }

        try:
            print(f"[LLM] Sending Request to {self.base_url} (Model: {self.model})")
            print(f"[LLM] Options: {final_options}")
            start = time.time()

            # ğŸ”¥ ä½¿ç”¨ Session å‘é€è¯·æ±‚ (è¶…é•¿ Timeout)ï¼Œå¤ç”¨ TCP è¿æ¥
            response = self.session.post(
                f"{self.base_url}/api/chat",
                json=payload,
                timeout=self.timeout
            )

            duration = time.time() - start
            print(f"[LLM] Response received in {duration:.2f}s ({duration / 60:.2f} minutes)")

            if response.status_code == 200:
                data = response.json()
                content = data.get("message", {}).get("content", "")
                if not content:
                    return "âš ï¸ æ¨¡å‹è¿”å›äº†ç©ºæ•°æ®ï¼Œè¯·æ£€æŸ¥æœ¬åœ° Ollama æ˜¾å­˜å ç”¨ã€‚"
                return content
            else:
                return f"âŒ Ollama API é”™è¯¯: Status {response.status_code} - {response.text}"

        except requests.exceptions.Timeout:
            return "âŒ ç”Ÿæˆè¶…æ—¶ã€‚ç”±äºç®—åŠ›é™åˆ¶ï¼Œæœ¬æ¬¡ä»»åŠ¡è€—æ—¶è¶…è¿‡ 60 åˆ†é’Ÿã€‚"
        except requests.exceptions.ConnectionError:
            return "âŒ æ— æ³•è¿æ¥åˆ° Ollama æœåŠ¡ã€‚è¯·ç¡®è®¤ Ollama å·²åœ¨åå°è¿è¡Œ (ç«¯å£ 11434)ã€‚"
        except Exception as e:
            print(f"âŒ LLM è¿æ¥å¤±è´¥: {e}")
            traceback.print_exc()
            return f"âš ï¸ AI æ€è€ƒä¸­æ–­: {str(e)}"